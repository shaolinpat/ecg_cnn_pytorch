{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e70ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "##\n",
    "##  Import Block\n",
    "##\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94f5cc",
   "metadata": {},
   "source": [
    "# ECG Classification Demo\n",
    "This notebook shows how we load data, train a 1D CNN, evaluate, and explain with Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59addb7e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils import resample\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Thread control\n",
    "torch.set_num_threads(6)\n",
    "print(\"Using\", torch.get_num_threads(), \"threads\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "################################################################################\n",
    "##\n",
    "##  ECGConvNet Class Definition\n",
    "##\n",
    "################################################################################\n",
    "\n",
    "\n",
    "class ECGConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=6)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 22, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "##\n",
    "##  Helper Functions\n",
    "##\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    cm, classes, normalize=False, title=\"Confusion matrix\", cmap=plt.cm.Blues\n",
    "):\n",
    "    \"\"\"\n",
    "    Comfusion matrix plotting\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        with np.errstate(all=\"ignore\"):\n",
    "            row_sums = cm.sum(axis=1, keepdims=True)\n",
    "            cm = np.divide(cm.astype(\"float\"), row_sums, where=row_sums != 0)\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "def evaluate_and_plot(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    train_accuracies,\n",
    "    val_accuracies,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    fold,\n",
    "    epochs,\n",
    "    out_folder,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate and plot a run\n",
    "    \"\"\"\n",
    "    labels = [0, 1, 2, 3, 4]\n",
    "    class_names = [\"N\", \"S\", \"V\", \"F\", \"Q\"]\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, labels=labels, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    plt.figure()\n",
    "    if len(train_accuracies) > 1:\n",
    "        plt.plot(train_accuracies, label=\"Training\")\n",
    "        plt.plot(val_accuracies, label=\"Validation\")\n",
    "    else:\n",
    "        plt.scatter([0], train_accuracies, label=\"Training\")\n",
    "        plt.scatter([0], val_accuracies, label=\"Validation\")\n",
    "    plt.title(\n",
    "        f\"Model Accuracy by Epoch\\n LR = {learning_rate}, BS = {batch_size}, Folds = {fold}, Epochs = {epochs}\"\n",
    "    )\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Model Accuracy\")\n",
    "    plt.legend()\n",
    "    out_file = f\"accuracy_{learning_rate}_{batch_size}_{fold}_{epochs}.png\"\n",
    "    full_path = os.path.join(out_folder, out_file)\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "    plot_confusion_matrix(\n",
    "        cm,\n",
    "        classes=class_names,\n",
    "        normalize=True,\n",
    "        title=f\"Normalized Confusion Matrix\\nLR={learning_rate}, BS={batch_size}, Fold={fold}, Epochs={epochs}\",\n",
    "    )\n",
    "    out_file = f\"matrix_{learning_rate}_{batch_size}_{fold}_{epochs}.png\"\n",
    "    full_path = os.path.join(out_folder, out_file)\n",
    "    plt.savefig(full_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def evaluate_on_ptb(\n",
    "    model_path, ptb_csv_path_normal, ptb_csv_path_abnormal, device, out_folder\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate a saved model on PTB dataset\n",
    "    \"\"\"\n",
    "    ptb_normal = pd.read_csv(ptb_csv_path_normal, header=None)\n",
    "    ptb_abnormal = pd.read_csv(ptb_csv_path_abnormal, header=None)\n",
    "    ptb_df = pd.concat([ptb_normal, ptb_abnormal], ignore_index=True)\n",
    "\n",
    "    ptb_df.dropna(inplace=True)\n",
    "    ptb_df[187] = ptb_df[187].astype(int)\n",
    "    ptb_df = ptb_df[ptb_df[187].isin([0, 1])]\n",
    "\n",
    "    X_ptb = ptb_df.iloc[:, :-1].values.reshape(-1, 1, 187)\n",
    "    y_ptb = ptb_df.iloc[:, -1].values\n",
    "\n",
    "    X_ptb_tensor = torch.tensor(X_ptb, dtype=torch.float32).to(device)\n",
    "    y_ptb_tensor = torch.tensor(y_ptb, dtype=torch.long)\n",
    "\n",
    "    loader = DataLoader(TensorDataset(X_ptb_tensor, y_ptb_tensor), batch_size=32)\n",
    "\n",
    "    # Load model\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = ECGConvNet().to(device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb)\n",
    "            pred = torch.argmax(out, dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            targets.extend(yb.numpy())\n",
    "\n",
    "    acc = np.mean(np.array(preds) == np.array(targets))\n",
    "    print(f\"\\n--- PTB Evaluation ---\")\n",
    "    print(f\"Model loaded from: {model_path}\")\n",
    "    print(f\"PTB Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(\"Classification Report (Classes 0 and 1 Only):\")\n",
    "    print(classification_report(targets, preds, labels=[0, 1], zero_division=0))\n",
    "\n",
    "    # Save classification report as CSV\n",
    "    report_dict = classification_report(\n",
    "        targets, preds, output_dict=True, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Keep only class 0 and 1 plus macro/weighted averages\n",
    "    keep_labels = [\"0\", \"1\", \"macro avg\", \"weighted avg\"]\n",
    "    filtered_report_dict = {k: v for k, v in report_dict.items() if k in keep_labels}\n",
    "\n",
    "    report_df = pd.DataFrame(filtered_report_dict).transpose()\n",
    "    ptb_report_path = os.path.join(out_folder, \"ptb_classification_report.csv\")\n",
    "    report_df.to_csv(ptb_report_path)\n",
    "    print(f\"Saved PTB classification report to {ptb_report_path}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "\n",
    "    # Restrict to 0 and 1 classes only\n",
    "    cm = cm[:2, :2]\n",
    "    class_names = [\"Normal\", \"Abnormal\"]\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        cm, classes=class_names, normalize=True, title=\"PTB Normalized Confusion Matrix\"\n",
    "    )\n",
    "\n",
    "    ptb_outfile = os.path.join(out_folder, \"ptb_confusion_matrix.png\")\n",
    "    plt.savefig(ptb_outfile)\n",
    "    print(f\"Saved PTB confusion matrix to {ptb_outfile}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "##\n",
    "##  Main Processing\n",
    "##\n",
    "################################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    out_folder = \"./Outfiles_pytorch\"\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    mitbih_train_df = pd.read_csv(\"./data/mitbih_train.csv\", header=None)\n",
    "    mitbih_test_df = pd.read_csv(\"./data/mitbih_test.csv\", header=None)\n",
    "    combined_df = pd.concat((mitbih_train_df, mitbih_test_df), ignore_index=True)\n",
    "    combined_df[187] = combined_df[187].astype(int)\n",
    "    combined_df.dropna(inplace=True)\n",
    "    combined_df = combined_df.sample(frac=1, random_state=SEED)\n",
    "\n",
    "    # Extract features and labels\n",
    "    X = combined_df.iloc[:, :-1].values\n",
    "    y = combined_df.iloc[:, -1].values\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    param_grid = {\n",
    "        \"epochs_list\": [5, 10],\n",
    "        \"batch_size_list\": [10, 32],\n",
    "        \"learning_rate_list\": [1e-3, 5e-4, 1e-4],\n",
    "    }\n",
    "\n",
    "    param_combinations = list(\n",
    "        itertools.product(\n",
    "            param_grid[\"epochs_list\"],\n",
    "            param_grid[\"batch_size_list\"],\n",
    "            param_grid[\"learning_rate_list\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epochs, batch_size, learning_rate in tqdm(\n",
    "        param_combinations, desc=\"Grid Search\"\n",
    "    ):\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "            print(\n",
    "                f\"fold = {fold}, epoch = {epochs}, batch = {batch_size}, learning_rate = {learning_rate}\"\n",
    "            )\n",
    "\n",
    "            # Prepare data\n",
    "            X_train, X_val = torch.tensor(\n",
    "                X[train_idx], dtype=torch.float32\n",
    "            ), torch.tensor(X[val_idx], dtype=torch.float32)\n",
    "            y_train, y_val = torch.tensor(y[train_idx], dtype=torch.long), torch.tensor(\n",
    "                y[val_idx], dtype=torch.long\n",
    "            )\n",
    "            train_loader = DataLoader(\n",
    "                TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True\n",
    "            )\n",
    "            val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "            # Prepare model and training tools\n",
    "            model = ECGConvNet().to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "            fold_train_accuracies = []\n",
    "            fold_val_accuracies = []\n",
    "\n",
    "            # Track best model state\n",
    "            best_val_acc = -1.0\n",
    "            best_model_state = None\n",
    "            best_model_params = {}\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                running_train_loss = 0.0\n",
    "\n",
    "                for xb, yb in train_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(xb)\n",
    "                    loss = criterion(outputs, yb)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_train_loss += loss.item()\n",
    "\n",
    "                # Evaluate\n",
    "                model.eval()\n",
    "                train_preds, train_targets = [], []\n",
    "                val_preds, val_targets = [], []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for xb_, yb_ in train_loader:\n",
    "                        xb_ = xb_.to(device)\n",
    "                        out = model(xb_)\n",
    "                        preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "                        train_preds.extend(preds)\n",
    "                        train_targets.extend(yb_.numpy())\n",
    "\n",
    "                    for xb_, yb_ in val_loader:\n",
    "                        xb_ = xb_.to(device)\n",
    "                        out = model(xb_)\n",
    "                        preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "                        val_preds.extend(preds)\n",
    "                        val_targets.extend(yb_.numpy())\n",
    "\n",
    "                # Capture model accuracy and loss ===\n",
    "                train_acc = np.mean(np.array(train_preds) == np.array(train_targets))\n",
    "                val_acc = np.mean(np.array(val_preds) == np.array(val_targets))\n",
    "                avg_train_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "                # Save best model state by validation accuracy\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model_state = model.state_dict()\n",
    "                    best_model_params = {\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"fold\": fold,\n",
    "                    }\n",
    "\n",
    "                fold_train_accuracies.append(train_acc)\n",
    "                fold_val_accuracies.append(val_acc)\n",
    "                train_losses.append(avg_train_loss)\n",
    "\n",
    "                running_val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for xb, yb in val_loader:\n",
    "                        xb, yb = xb.to(device), yb.to(device)\n",
    "                        out = model(xb)\n",
    "                        loss = criterion(out, yb)\n",
    "                        running_val_loss += loss.item()\n",
    "\n",
    "                avg_val_loss = running_val_loss / len(val_loader)\n",
    "                val_losses.append(avg_val_loss)\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1}/{epochs} - Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Validation Accuracy: {val_acc:.4f}\"\n",
    "                )\n",
    "\n",
    "            # Save best model for this fold and grid combo\n",
    "            if best_model_state:\n",
    "                model_path = os.path.join(\n",
    "                    out_folder,\n",
    "                    f\"best_model_lr{learning_rate}_bs{batch_size}_fold{fold}_ep{epochs}.pt\",\n",
    "                )\n",
    "                torch.save(\n",
    "                    {\"model_state_dict\": best_model_state, \"params\": best_model_params},\n",
    "                    model_path,\n",
    "                )\n",
    "                print(f\"Saved best model to {model_path}\")\n",
    "\n",
    "            # Plot losses losses\n",
    "            plt.figure()\n",
    "            plt.plot(train_losses, label=\"Training\")\n",
    "            plt.plot(val_losses, label=\"Validation\")\n",
    "            plt.title(\n",
    "                f\"Model Loss by Epoch\\nLR={learning_rate}, BS={batch_size}, Fold={fold}, Epochs={epochs}\"\n",
    "            )\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Model Loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(\n",
    "                f\"{out_folder}/loss_{learning_rate}_{batch_size}_{fold}_{epochs}.png\"\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            # Plot losses accuracy\n",
    "            plt.figure()\n",
    "            plt.plot(fold_train_accuracies, label=\"Training\")\n",
    "            plt.plot(fold_val_accuracies, label=\"Validation\")\n",
    "            plt.title(\n",
    "                f\"Model Accuracy by Epoch\\nLR={learning_rate}, BS={batch_size}, Fold={fold}, Epochs={epochs}\"\n",
    "            )\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Model Accuracy\")\n",
    "            plt.legend()\n",
    "            plt.savefig(\n",
    "                f\"{out_folder}/accuracy_{learning_rate}_{batch_size}_{fold}_{epochs}.png\"\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            # Final eval and print confusion martrix\n",
    "            y_true, y_pred = [], []\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb = xb.to(device)\n",
    "                    out = model(xb)\n",
    "                    preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "                    y_pred.extend(preds)\n",
    "                    y_true.extend(yb.numpy())\n",
    "\n",
    "            acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
    "            results.append(\n",
    "                {\n",
    "                    \"fold\": fold,\n",
    "                    \"epochs\": epochs,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"val_accuracy\": round(acc, 4),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            evaluate_and_plot(\n",
    "                y_true,\n",
    "                y_pred,\n",
    "                fold_train_accuracies,\n",
    "                fold_val_accuracies,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                fold,\n",
    "                epochs,\n",
    "                out_folder,\n",
    "            )\n",
    "\n",
    "    # Save file with running results\n",
    "    pd.DataFrame(results).to_csv(\"results_summary_pytorch.csv\", index=False)\n",
    "    print(\"Saved results to results_summary_pytorch.csv\")\n",
    "\n",
    "    ############################################################################\n",
    "    ##\n",
    "    ## PTB Validation\n",
    "    ##\n",
    "    ############################################################################\n",
    "\n",
    "    # Select best model for running on PTB data\n",
    "    results_df = pd.read_csv(\"results_summary_pytorch.csv\")\n",
    "    best_row = results_df.loc[results_df[\"val_accuracy\"].idxmax()]\n",
    "    lr = best_row[\"learning_rate\"]\n",
    "    bs = best_row[\"batch_size\"]\n",
    "    fold = best_row[\"fold\"]\n",
    "    ep = best_row[\"epochs\"]\n",
    "\n",
    "    # Evaluate saved best model on PTB dataset\n",
    "    best_model_path = f\"./Outfiles_pytorch/best_model_lr{lr}_bs{int(bs)}_fold{int(fold)}_ep{int(ep)}.pt\"\n",
    "    ptb_csv_path_normal = \"./data/ptbdb_normal.csv\"\n",
    "    ptb_csv_path_abnormal = \"./data/ptbdb_abnormal.csv\"\n",
    "\n",
    "    if os.path.exists(best_model_path):\n",
    "        evaluate_on_ptb(\n",
    "            best_model_path,\n",
    "            ptb_csv_path_normal,\n",
    "            ptb_csv_path_abnormal,\n",
    "            device,\n",
    "            out_folder,\n",
    "        )\n",
    "\n",
    "        # Generate LaTeX table from PTB report\n",
    "        report_csv_path = os.path.join(out_folder, \"ptb_classification_report.csv\")\n",
    "        if os.path.exists(report_csv_path):\n",
    "            df = pd.read_csv(report_csv_path, index_col=0)\n",
    "            df = df.round(3)\n",
    "            df[\"support\"] = df[\"support\"].astype(int)\n",
    "            df = df[[\"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
    "\n",
    "            table_body = df.to_latex(index=True, column_format=\"lcccc\")\n",
    "            latex_code = (\n",
    "                r\"\"\"\n",
    "            \\begin{table}[H]\n",
    "                \\centering\n",
    "                \\caption{PTB Classification Report (Normal vs. Abnormal)}\n",
    "                \\label{tab:ptb_classification}\n",
    "                \"\"\"\n",
    "                + table_body\n",
    "                + r\"\"\"\n",
    "                \\end{table}\n",
    "            \"\"\"\n",
    "            )\n",
    "            latex_path = os.path.join(out_folder, \"ptb_report_table.tex\")\n",
    "            with open(latex_path, \"w\") as f:\n",
    "                f.write(latex_code)\n",
    "            print(f\"Saved LaTeX report to {latex_path}\")\n",
    "        else:\n",
    "            print(\"PTB classification report not found. Skipping LaTeX export.\")\n",
    "    else:\n",
    "        print(f\"Model file not found: {best_model_path}\")\n",
    "\n",
    "    # Close out\n",
    "    time_spent = (time.time() - start_time) / 60\n",
    "    print(f\"Processing time: {time_spent:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc280e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "primary": "py:percent"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
